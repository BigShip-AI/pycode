### 知乎回答多线程爬虫

**模式**

1. 单问题爬取模式

2. 相似问题爬取模式

**输出**

​	**文件名** 问题题目

​	**文件内容**

1. 问题
2. 问题id
3. 回答者昵称
4. 回答者空间id
5. 回答者id
6. 回答者内容

**单问题爬取模式**

​	**功能** 主要通过用户提供的问题id，爬取单个问题下的所有回答

**相似问题爬取模式**

​	**功能** 通过用户提供的起始问题id，以及相关内容爬取数量，利用知乎的**相关问题**进行自动检索，并不断递归至用户提供的爬取数量（默认数量为20）。

**bug** 由于知乎具有一定的反爬，所以在相似问题检索时最大的检索量为400，如果到达500就会触发反爬机制，需要用户填写一个验证码才可以继续爬取。（也许未来有时间的话会把获取验证码的部分代码补全，但具体机器打码的实现还是太难了，所以还得自己手动输入验证码）

**优点** 简单，明了，使用requests库进行爬取，利用递归实现迭代检索，代码量不大。

**缺点** 功能较少，对线程的把握不够好，可能会出现数据少量缺失的情况。

**技术栈：**

1. requests
2. re
3. json
4. time
5. threading

**未来** 关于知乎的爬取，我这里还有一个存货——爬取知乎文章中的表情包（gif，png，jpg），这样就可以愉快的收集表情包了。同时我也尝试着去做了一下对知乎用户数据的爬取，但还为成功。

**更新**

- 2021.1.4

  更新基础功能

- 2021.9.9

  更新IP代理池，同时对原有代码进行了一点优化，修复原先的重复重复爬取问题，现版本对多问题爬取的最大数量已没有明确约束了，代理池的具体使用方法参考[这里](https://github.com/srx-2000/git_spider/tree/master/proxy_pool)

